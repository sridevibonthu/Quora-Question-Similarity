{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Question similarity attempt2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMD9EJkVbhkDo68CMgF2+Xb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAc3oZqmozrX"
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJuqJh2pDQPI",
        "outputId": "25980d09-0c5d-4546-f9d0-9b402faeaa15"
      },
      "source": [
        "!python -m spacy download en\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "zlkEmGLfo04i",
        "outputId": "6f579686-3861-4a24-9486-c16054b7a518"
      },
      "source": [
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa7609b4-08ac-4773-a80d-d47dddf83c09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa7609b4-08ac-4773-a80d-d47dddf83c09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Jdo7Pk0Tyh"
      },
      "source": [
        "!cat kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNnJ1cI71-69",
        "outputId": "94e64909-af54-4afd-f0ca-dfb9b40a4c1d"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8hW6UpJpDiz",
        "outputId": "4fe424ec-9864-4617-f112-7ea5f4bc34f6"
      },
      "source": [
        "#Download data\n",
        "!kaggle competitions download -c quora-question-pairs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/4.95M [00:00<?, ?B/s]\n",
            "100% 4.95M/4.95M [00:00<00:00, 45.6MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 89% 102M/114M [00:01<00:00, 67.2MB/s] \n",
            "100% 114M/114M [00:01<00:00, 90.9MB/s]\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading train.csv.zip to /content\n",
            " 43% 9.00M/21.2M [00:00<00:00, 27.8MB/s]\n",
            "100% 21.2M/21.2M [00:00<00:00, 50.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA2nJbHjpQEW"
      },
      "source": [
        "!unzip -q train.csv.zip -d .\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wzI7WJ2M2bDr",
        "outputId": "4bb72e8b-b4d7-4218-c26d-e7ce16674b12"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "#import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "#from bs4 import BeautifulSoup\n",
        "\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy.data import Field, BucketIterator\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1OsfQUjB2J7r",
        "outputId": "30f49a28-0d6c-4825-8c21-719d6196957d"
      },
      "source": [
        "df = pd.read_csv(\"/content/train.csv\",encoding='latin-1')\n",
        "df = df.fillna('')\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjjvWBdn2iQT",
        "outputId": "4eb9f2d2-fd96-4839-ac05-ebdf3dce03a5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404290, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrp_IFrRxc4t"
      },
      "source": [
        "spacy_text = spacy.load('en')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTC5l8DEvq5w"
      },
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZpB6baJwLcn"
      },
      "source": [
        "def tokenize_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_text.tokenizer(text)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXRGCEOExpD4"
      },
      "source": [
        "\n",
        "Q1 = Field(tokenize = tokenize_text,\n",
        "           init_token = '<sos>',\n",
        "           eos_token = '<eos>',\n",
        "           lower = True,\n",
        "           batch_first = True)\n",
        "\n",
        "Q2 = Field(tokenize = tokenize_text,\n",
        "           init_token = '<sos>',\n",
        "           eos_token = '<eos>',\n",
        "           lower = True,\n",
        "           batch_first = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPz7OjRyJsKB"
      },
      "source": [
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VR6ygCGysJB"
      },
      "source": [
        "fields = [('q1', Q1), ('q2', Q2), ('label', LABEL)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hje2yTSYCJwa"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.question1[i], df.question2[i], df.is_duplicate[i]], fields) for i in range(df.shape[0])]\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH2QXgWcCdPG"
      },
      "source": [
        "Dataset = torchtext.legacy.data.Dataset(example, fields)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBwDyOYDMNE",
        "outputId": "19ac7907-d618-4610-c568-c0981ea4dc12"
      },
      "source": [
        "(train_data, valid_data) = Dataset.split(split_ratio= [0.25, 0.75], random_state = random.seed(SEED))\n",
        "len(train_data), len(valid_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101072, 303218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Si3iWQDdmT"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "Q1.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "Q2.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i8drUALJoYk"
      },
      "source": [
        "we have to build vocabulary on both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytvEky98ImXT",
        "outputId": "b2aaca0b-ecd8-468d-98dd-be7a0b733b17"
      },
      "source": [
        "\n",
        "print(f\"Unique tokens in Question 1 vocabulary: {len(Q1.vocab)}\")\n",
        "print(f\"Unique tokens in Question 2 vocabulary: {len(Q2.vocab)}\")\n",
        "print(f\"Unique tokens in Label vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in Question 1 vocabulary: 25004\n",
            "Unique tokens in Question 2 vocabulary: 25004\n",
            "Unique tokens in Label vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJASSMKMOy-L",
        "outputId": "86ddc13b-85b7-4405-8a08-8eec1deda6da"
      },
      "source": [
        "print(vars(train_data[10]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'q1': ['is', 'nothing', 'free', 'in', 'this', 'world', '?'], 'q2': ['why', 'is', 'nothing', 'free', 'in', 'this', 'world', '?'], 'label': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYfo3nVXJLJf"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhIJu2sQJcL_"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx ):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    #packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "    outputs, (hidden, cell) = self.lstm(embedded)\n",
        "    #output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "    hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "    return self.fc(hidden)\n",
        "    #return hidden\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMMRbeRs28w"
      },
      "source": [
        "class SiameseLSTM(nn.Module):\n",
        "  def __init__(self, encoder, device):\n",
        "    super().__init__()\n",
        "    self.encoder1 = encoder\n",
        "    self.encoder2 = encoder\n",
        "    self.device = device\n",
        "  def forward(self, q1, q2):\n",
        "    output1 = self.encoder1(q1)\n",
        "    output2 = self.encoder2(q2)\n",
        "\n",
        "    #print(output1.shape, output2.shape)\n",
        "\n",
        "    #distance\n",
        "    dist = torch.exp(- torch.sum(torch.abs(output1 - output2), dim=1, keepdim=True))\n",
        "    #dist = torch.dist(output1, output2, p=2)\n",
        "    return dist\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmYvcYy6qBiB"
      },
      "source": [
        "INPUT_DIM = len(Q1.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 128\n",
        "N_LAYERS = 3\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = Q1.vocab.stoi[Q1.pad_token]\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGlvYLQ0uDk3"
      },
      "source": [
        "model = SiameseLSTM(enc, device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTMOzIa-qWCJ",
        "outputId": "63dc51f7-637a-41fa-ff74-af3507d65aab"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseLSTM(\n",
              "  (encoder1): Encoder(\n",
              "    (embedding): Embedding(25004, 100, padding_idx=1)\n",
              "    (lstm): LSTM(100, 128, num_layers=3, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encoder2): Encoder(\n",
              "    (embedding): Embedding(25004, 100, padding_idx=1)\n",
              "    (lstm): LSTM(100, 128, num_layers=3, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFtR372Cr28E",
        "outputId": "2adb82d8-1e96-4ac1-f7e6-81e9da5a7875"
      },
      "source": [
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseLSTM(\n",
              "  (encoder1): Encoder(\n",
              "    (embedding): Embedding(25004, 100, padding_idx=1)\n",
              "    (lstm): LSTM(100, 128, num_layers=3, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encoder2): Encoder(\n",
              "    (embedding): Embedding(25004, 100, padding_idx=1)\n",
              "    (lstm): LSTM(100, 128, num_layers=3, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Cjxub8sBhy",
        "outputId": "7e37f665-0a5f-434b-8454-45c443a9989b"
      },
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,559,344 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waqj00Y0sIvM"
      },
      "source": [
        "\n",
        "LEARNING_RATE = 0.003\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXBu2UNvFzg4"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, dist, label):\n",
        "\n",
        "        #if label=0, maximize dist and if label=1, minimize the distance\n",
        "        loss_contrastive = torch.mean(1/2*(label) * torch.pow(dist, 2) +\n",
        "                                      1/2*(1-label) * torch.pow(F.relu(self.margin - dist), 2)\n",
        "                                      )\n",
        "        return loss_contrastive"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORI6wZreF6qH"
      },
      "source": [
        "criterion = ContrastiveLoss()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BJRph6THXxx"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ixzv1zHpso"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion): \n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    q1 = batch.q1\n",
        "    q2 = batch.q2\n",
        "    label = batch.label\n",
        "    #print(q1, q2, label)\n",
        "\n",
        "    maxsize = max(q1[0].shape, q2[0].shape)\n",
        "    #print(maxsize)\n",
        "\n",
        "    \n",
        "    if q1.shape[1] < maxsize[0]:\n",
        "      #print(\"padding q1\")\n",
        "      to_be_padded_shape = ( q1.shape[0], maxsize[0] - q1.shape[1])\n",
        "      padding = torch.zeros(to_be_padded_shape, dtype=torch.int64, device=device)\n",
        "      q1 = torch.cat((q1, padding), dim=1)\n",
        "    else:\n",
        "      #print(\"padding q2\")\n",
        "      to_be_padded_shape = ( q2.shape[0], maxsize[0] - q2.shape[1])\n",
        "      padding = torch.zeros(to_be_padded_shape, dtype=torch.int64, device=device)\n",
        "      q2 = torch.cat((q2, padding), dim=1)\n",
        "\n",
        "    #q1 = q1.to(device)\n",
        "    #\n",
        "    q2 = q2.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(q1, q2)\n",
        "\n",
        "    \n",
        "\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    if (i%25 == 0):\n",
        "      print(output[0].item(), label[0].item())\n",
        "    if (i%200 == 0):\n",
        "      print(\"Loss\", loss.item())\n",
        "  \n",
        "  return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGLfqouNFYik",
        "outputId": "40ed8d3f-1c7b-466d-d6ed-575ab9797a0c"
      },
      "source": [
        "a = torch.randn((4,4))\n",
        "a[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9661, -1.1189,  0.7667,  1.9898])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuckIe1G2brj",
        "outputId": "7c4d22b2-e94d-435c-b7e3-de921518c90d"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "  print(f'\\tEpoch : {epoch} --- Train Loss: {train_loss:.3f}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6722813844680786 0.0\n",
            "Loss 0.11917537450790405\n",
            "0.593150794506073 0.0\n",
            "0.5140672922134399 0.0\n",
            "0.6633709669113159 0.0\n",
            "0.5850601196289062 1.0\n",
            "0.6540926694869995 1.0\n",
            "0.6086536645889282 0.0\n",
            "0.6347788572311401 0.0\n",
            "0.5939784049987793 0.0\n",
            "Loss 0.11503319442272186\n",
            "0.5712102651596069 0.0\n",
            "0.6216328144073486 0.0\n",
            "0.6278300881385803 1.0\n",
            "0.6403073668479919 0.0\n",
            "0.6027401685714722 0.0\n",
            "0.5822219848632812 0.0\n",
            "0.5774683952331543 1.0\n",
            "\tEpoch : 0 --- Train Loss: 0.117\n",
            "0.6700252890586853 0.0\n",
            "Loss 0.11067039519548416\n",
            "0.5885022878646851 0.0\n",
            "0.6223042607307434 0.0\n",
            "0.611527681350708 0.0\n",
            "0.6356885433197021 1.0\n",
            "0.6825144290924072 1.0\n",
            "0.6343337893486023 1.0\n",
            "0.616695761680603 1.0\n",
            "0.5980194807052612 1.0\n",
            "Loss 0.11394061893224716\n",
            "0.6224979162216187 1.0\n",
            "0.6257814168930054 0.0\n",
            "0.6610662341117859 0.0\n",
            "0.6571629643440247 1.0\n",
            "0.5777915120124817 0.0\n",
            "0.6523122787475586 0.0\n",
            "0.7085046172142029 0.0\n",
            "\tEpoch : 1 --- Train Loss: 0.117\n",
            "0.592287003993988 1.0\n",
            "Loss 0.11996766924858093\n",
            "0.6009474396705627 1.0\n",
            "0.6304569244384766 1.0\n",
            "0.6318252086639404 0.0\n",
            "0.6761813163757324 0.0\n",
            "0.6247540712356567 0.0\n",
            "0.627144992351532 0.0\n",
            "0.6335271596908569 1.0\n",
            "0.6643741726875305 1.0\n",
            "Loss 0.11864786595106125\n",
            "0.6732454299926758 0.0\n",
            "0.5991325974464417 0.0\n",
            "0.6416918039321899 1.0\n",
            "0.6347982883453369 1.0\n",
            "0.6398686170578003 1.0\n",
            "0.6458336114883423 1.0\n",
            "0.630029022693634 1.0\n",
            "\tEpoch : 2 --- Train Loss: 0.117\n",
            "0.6408261656761169 0.0\n",
            "Loss 0.11799142509698868\n",
            "0.6383047699928284 0.0\n",
            "0.655978262424469 1.0\n",
            "0.6864476203918457 0.0\n",
            "0.5844953656196594 0.0\n",
            "0.6213193535804749 0.0\n",
            "0.6113300919532776 0.0\n",
            "0.6133547425270081 1.0\n",
            "0.5898157358169556 1.0\n",
            "Loss 0.12146709859371185\n",
            "0.6165158748626709 0.0\n",
            "0.6244232654571533 0.0\n",
            "0.6179900765419006 0.0\n",
            "0.6254870295524597 1.0\n",
            "0.6394721865653992 1.0\n",
            "0.6193055510520935 1.0\n",
            "0.6344417929649353 0.0\n",
            "\tEpoch : 3 --- Train Loss: 0.117\n",
            "0.6123000383377075 1.0\n",
            "Loss 0.11538639664649963\n",
            "0.6434998512268066 0.0\n",
            "0.6279124617576599 0.0\n",
            "0.6338567733764648 1.0\n",
            "0.6555372476577759 1.0\n",
            "0.6304655075073242 1.0\n",
            "0.5960670113563538 1.0\n",
            "0.6186236143112183 1.0\n",
            "0.6360268592834473 1.0\n",
            "Loss 0.12611930072307587\n",
            "0.6080708503723145 0.0\n",
            "0.6198014616966248 0.0\n",
            "0.6441776156425476 0.0\n",
            "0.6473023891448975 0.0\n",
            "0.6147185564041138 0.0\n",
            "0.6159746050834656 1.0\n",
            "0.6166878342628479 1.0\n",
            "\tEpoch : 4 --- Train Loss: 0.117\n",
            "0.643286943435669 0.0\n",
            "Loss 0.1155209094285965\n",
            "0.6332274675369263 1.0\n",
            "0.6200117468833923 0.0\n",
            "0.6159034371376038 0.0\n",
            "0.6252332329750061 1.0\n",
            "0.5923346877098083 1.0\n",
            "0.6068595051765442 0.0\n",
            "0.6504536271095276 0.0\n",
            "0.6318966150283813 1.0\n",
            "Loss 0.11590605974197388\n",
            "0.6152667999267578 0.0\n",
            "0.6267289519309998 1.0\n",
            "0.6065964102745056 0.0\n",
            "0.6344187259674072 0.0\n",
            "0.6472534537315369 1.0\n",
            "0.5656522512435913 1.0\n",
            "0.6124234199523926 0.0\n",
            "\tEpoch : 5 --- Train Loss: 0.117\n",
            "0.6105647683143616 0.0\n",
            "Loss 0.1253151297569275\n",
            "0.6305271983146667 1.0\n",
            "0.6203435063362122 0.0\n",
            "0.60371994972229 0.0\n",
            "0.606773853302002 0.0\n",
            "0.6675198674201965 1.0\n",
            "0.676167368888855 0.0\n",
            "0.6272919178009033 0.0\n",
            "0.6725780367851257 1.0\n",
            "Loss 0.1113588884472847\n",
            "0.6875632405281067 1.0\n",
            "0.6550588607788086 1.0\n",
            "0.6153960824012756 0.0\n",
            "0.6233132481575012 1.0\n",
            "0.5981531143188477 0.0\n",
            "0.5861945152282715 0.0\n",
            "0.6256203651428223 0.0\n",
            "\tEpoch : 6 --- Train Loss: 0.117\n",
            "0.6750056743621826 0.0\n",
            "Loss 0.11487158387899399\n",
            "0.7005900740623474 1.0\n",
            "0.6411016583442688 0.0\n",
            "0.6255667209625244 0.0\n",
            "0.6521551609039307 0.0\n",
            "0.638332724571228 1.0\n",
            "0.5846899151802063 0.0\n",
            "0.6490495204925537 0.0\n",
            "0.6458499431610107 1.0\n",
            "Loss 0.11528798937797546\n",
            "0.5800607800483704 0.0\n",
            "0.6431548595428467 1.0\n",
            "0.6663365364074707 0.0\n",
            "0.6275901198387146 0.0\n",
            "0.6538046598434448 0.0\n",
            "0.6597372889518738 0.0\n",
            "0.6251188516616821 1.0\n",
            "\tEpoch : 7 --- Train Loss: 0.117\n",
            "0.5776848196983337 0.0\n",
            "Loss 0.11599663645029068\n",
            "0.6797011494636536 1.0\n",
            "0.6478836536407471 0.0\n",
            "0.622428297996521 1.0\n",
            "0.647079348564148 0.0\n",
            "0.6212999224662781 1.0\n",
            "0.6020786762237549 0.0\n",
            "0.6525821685791016 0.0\n",
            "0.6775264143943787 1.0\n",
            "Loss 0.11843656748533249\n",
            "0.6194780468940735 1.0\n",
            "0.6556835770606995 0.0\n",
            "0.6395095586776733 0.0\n",
            "0.6146677136421204 0.0\n",
            "0.6609876155853271 0.0\n",
            "0.6573094129562378 0.0\n",
            "0.6045212745666504 0.0\n",
            "\tEpoch : 8 --- Train Loss: 0.117\n",
            "0.6217774748802185 1.0\n",
            "Loss 0.11532880365848541\n",
            "0.5935800075531006 1.0\n",
            "0.5819346904754639 0.0\n",
            "0.6151643991470337 0.0\n",
            "0.616516649723053 0.0\n",
            "0.5810034275054932 0.0\n",
            "0.6271888613700867 0.0\n",
            "0.6108397841453552 0.0\n",
            "0.6028221249580383 1.0\n",
            "Loss 0.11596477031707764\n",
            "0.591062605381012 1.0\n",
            "0.6303389072418213 0.0\n",
            "0.6374158263206482 0.0\n",
            "0.6004469394683838 1.0\n",
            "0.654676616191864 0.0\n",
            "0.6098932027816772 0.0\n",
            "0.6480294466018677 1.0\n",
            "\tEpoch : 9 --- Train Loss: 0.117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oITpsbBZHeQI"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ZJF3PsGcm_"
      },
      "source": [
        "if T.q1.shape[1] < maxsize[0]:\n",
        "  print(\"padding q1\")\n",
        "  to_be_padded_shape = ( T.q1.shape[0], maxsize[0] - T.q1.shape[1])\n",
        "  padding = torch.zeros(to_be_padded_shape, dtype=torch.int64)\n",
        "  T.q1 = torch.cat((T.q1, padding), dim=1)\n",
        "else:\n",
        "  print(\"padding q2\")\n",
        "  to_be_padded_shape = ( T.q2.shape[0], maxsize[0] - T.q2.shape[1])\n",
        "  padding = torch.zeros(to_be_padded_shape, dtype=torch.int64)\n",
        "  T.q2 = torch.cat((T.q2, padding), dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxeicQuaGjsm"
      },
      "source": [
        "T.q1.shape, T.q2.shape, padding.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVnx3mzuIgLJ"
      },
      "source": [
        "T.q2[0].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvePx05ewBNc"
      },
      "source": [
        "outcome = model(T.q1, T.q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mdlWZizwQ7L"
      },
      "source": [
        "outcome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYr66SVpJwAc"
      },
      "source": [
        "T.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW9LUF7U3aCr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}